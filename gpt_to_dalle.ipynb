{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up keys and object\n",
    "To run this example, you need an api key and org key. To run the whole example it costs 6K to 7K tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "execfile('./lib.py')\n",
    "import os\n",
    "\n",
    "removeEnd = { \"50256\": -100 }\n",
    "api_key = open_file('api_key.txt')\n",
    "org_key = open_file('org_key.txt')\n",
    "model = \"text-davinci-003\"\n",
    "\n",
    "gptComp = GptCompletion(api_key, org_key, model)\n",
    "imageCreator = ImageCreation(api_key, org_key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API Call Configurations\n",
    "Completions have a habit of ending prematurely so this is configured to prefer not to use the ending token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "requestConfig = {\n",
    "    \"max_tokens\": 200,\n",
    "    \"temperature\": 1,\n",
    "    \"logit_bias\": removeEnd\n",
    "}\n",
    "\n",
    "improvementConfig = {\n",
    "    \"max_tokens\": 100\n",
    "}\n",
    "\n",
    "pickConfig = {\n",
    "    \"max_tokens\": 100,\n",
    "    \"logit_bias\": removeEnd\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompts\n",
    "**obj:** the subject of the image, the user input to the program. In this example it is a nurse  \n",
    "**examples:** Currently the model needs a few examples, more powerful nlp models in the future may not need this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = \"nurse\"\n",
    "\n",
    "def requestPrompt(ex):\n",
    "    return \\\n",
    "        \"Write a few prompts for a text to image model that describes a \" + obj + \" \\n\\\n",
    "        This prompt must be diverse in its output. \\n\\\n",
    "        Try to include these ideas in the prompts: diversity, specificity, imagination, detail, and emotion.\\n\\\n",
    "        Use language that paints a picture.\\n\\\n",
    "        The example prompts are incomplete, but the new prompts are filled in.\\n\\n\\\n",
    "        Example Prompts:\" + concatList('', ex, '\\n- ')  + \"\\n\\nNew Prompts:\"\n",
    "\n",
    "examples = [\n",
    "    \"A male nurse of asian descent is checking the vital signs of a patient in a hospital\",\n",
    "    \"A female nurse of african descent is administering medication to a patient in a hospital bed\",\n",
    "    \"A male nurse of hispanic heritage is comforting a child patient in a pediatric unit\"\n",
    "]\n",
    "\n",
    "def improvementPrompt(p):\n",
    "    return \\\n",
    "        \"How would you improve these prompts for a text to image model?\\n \\\n",
    "        Include these ideas: diversity, specificity, imagination, detail, and emotion.\\n \\\n",
    "        Keep the prompt as short as possible.\\n \\\n",
    "        Promts:\\n\" \\\n",
    "        + p + \"\\n\\nBEGIN IMPROVED PROMPTS\\n\"\n",
    "\n",
    "def pickPrompts(prompts):\n",
    "    return \\\n",
    "        \"This is a list of prompts for a text to image model.\\n\\\n",
    "        Pick the top 3 prompts from this list:\\n\" + prompts + \\\n",
    "        \"\\nBest prompts:\\n\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate prompts\n",
    "This will create 5 to 10 prompts for Dall-e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- A female nurse of caucasian background is gently placing her hand on an elderly patient's shoulder in a nursing home\n",
      "- In a hospital trauma unit, a male nurse of native american descent is urgently tending to a critically injured patient\n",
      "- A female nurse of east-asian origin is intently observing a patient's monitoring equipment in an intensive care unit\n",
      "- A male nurse of middle-eastern descent is sharing a kind word with a cancer patient in an oncology ward\n",
      "- In a specialized children's hospital, a female nurse of south-asian heritage is helping to cheer up a sick child with a present\n",
      "- A male nurse of african descent is tending to a new mother in the maternity ward with a gentle smile on his face. \n",
      "- In the emergency room, a female nurse of mixed race is swiftly and attentively attending to a patient with a life-threatening injury \n",
      "- A male nurse of mediterranean descent is consoling a termin\n"
     ]
    }
   ],
   "source": [
    "res = gptComp.complete(requestPrompt(examples), config=requestConfig)\n",
    "print(res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick the top results\n",
    "Use GPT3 to pick the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. A female nurse of caucasian background is gently placing her hand on an elderly patient's shoulder in a nursing home.\n",
      "2. In a hospital trauma unit, a male nurse of native american descent is urgently tending to a critically injured patient.\n",
      "3. In a specialized children's hospital, a female nurse of south-asian heritage is helping to cheer up a sick child with a present. \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "res = gptComp.complete(pickPrompts(res), config=pickConfig)\n",
    "print(res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ask to do better\n",
    "Generally, the longer GPT3 has to think about something, the better the end product is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. A female nurse of caucasian descent with a kind smile warmly puts her arm around an elderly patient in a nursing home. \n",
      "2. In a hustling and bustling hospital trauma unit, a male nurse of native american descent intently works to save the life of a critically injured patient. \n",
      "3. In a solemn children's hospital, a female nurse of south-asian heritage gifts a sick child with a toy to bring them joy and comfort.\n"
     ]
    }
   ],
   "source": [
    "res = gptComp.complete(improvementPrompt(res), config=improvementConfig)\n",
    "print(res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the image\n",
    "Each prompt should be in its own line, this will generate the last image in the list using the Dall-e api. Image names are made from the uuid of the download url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image downloaded to: 9a8a5e05-7219-35d2-b1e8-68abb2fa0148.png\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('images'):\n",
    "    os.makedirs('images')\n",
    "\n",
    "l = res.split('\\n')\n",
    "imageCreator.download('images', l[2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put it all together\n",
    "A simple function to create 4 prompts using the method above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - A Native American female nurse is tending to an IV drip in a cheery hospital room.\n",
      " - An elderly European nurse is cradling a child's hand with love in a pediatric unit.\n",
      " - A young African American male nurse wheels a patient to surgery with a worried expression.\n",
      " - A South Asian female nurse is carefully taking a patient's vital signs with comforting movements.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def getBestPrompts(ex):\n",
    "    promptResults = gptComp.complete(requestPrompt(ex), requestConfig)\n",
    "    res = gptComp.complete(pickPrompts(promptResults), config=pickConfig)\n",
    "    res = gptComp.complete(improvementPrompt(res), improvementConfig)\n",
    "    return reformatPrompts(res)\n",
    "\n",
    "bp = getBestPrompts(examples)\n",
    "print(bp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bulk create\n",
    "This is another simple function that will create n prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A proud indigenous female nurse carefully examines an elderly patient in a sun\n",
      "soaked medical ward with ivy\n",
      "covered walls.\n",
      " \n",
      " A knowledgeable Middle Eastern male nurse takes the blood pressure of a struggling patient in an urgent care unit.\n",
      " \n",
      " A passionate Caribbean female nurse comforts a young patient with a warm smile in a bustling urban clinic.\n",
      "\n",
      " Reverently, a female Indigenous nurse carefully attends to an elderly patient in a hospice center.\n",
      " \n",
      " With compassion, a male African American nurse brings relief and comfort to a patient with a therapeutic massage in an intensive care unit.\n",
      " \n",
      " Caringly, a female Irish nurse tenderly administers a flu shot to a new mother in a birthing center.\n",
      "\n",
      " A female nurse of Native American descent is beaming with joy as she embraces an elderly hospice patient in a tender hug. \n",
      " \n",
      " A male nurse of African heritage cradles a baby lovingly in his arms while taking a temperature in a birthing center. \n",
      " \n",
      " A female nurse of European descent lovingly meets the gaze of a frightened child in the pediatric emergency room. \n",
      " \n",
      " A female nurse of Asian heritage wraps a comforting bandage around the arm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_prompts(num):\n",
    "    l = []\n",
    "    ex = examples\n",
    "    for _ in range(int(num/3)):\n",
    "        bp = getBestPrompts(ex)\n",
    "        for i in bp.split('-'):\n",
    "            l.append(i)\n",
    "    for p in l:\n",
    "        if p == ' ':\n",
    "            l.remove(p)\n",
    "    return l\n",
    "\n",
    "p = get_prompts(10)\n",
    "for i in p:\n",
    "    print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dall-e 2\n",
    "Once all the prompts have been created, send them to Dall-e to be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image downloaded to: 31394508-b6e5-31b6-8d80-35038f1323ab.png\n",
      "Image downloaded to: d2d0b20b-a9f5-3c1c-bcb9-bbaa137a8c44.png\n",
      "Image downloaded to: 7afd41ce-c989-39ec-8ba6-4f4d325d1a5c.png\n",
      "Image downloaded to: 3c51b767-de9b-342e-b593-a1c6d81489a9.png\n",
      "Image downloaded to: b6fa34ce-eacb-3f62-8b97-aa9c217e6a7b.png\n",
      "Image downloaded to: 5a5aa4da-2da8-3ff2-8971-a6b91d031333.png\n",
      "Image downloaded to: ccf7533b-fdc5-3ec1-96f6-ca5b35b0b499.png\n",
      "Image downloaded to: 3913d9e3-bf08-3ca3-b139-08538c4c1100.png\n",
      "Image downloaded to: b268adb9-cea9-37ed-b040-884bb4062059.png\n",
      "Image downloaded to: 2d910ac0-fd6e-3976-808f-83f7757021b9.png\n",
      "Image downloaded to: d0f2b238-37dd-3793-b121-2ae3bd71f877.png\n",
      "Image downloaded to: ea7ae2af-ba1c-39de-bb2e-a09d2a62bb46.png\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('images'):\n",
    "    os.makedirs('images')\n",
    "\n",
    "for im in p:\n",
    "    imageCreator.download('images', im)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total tokens used\n",
    "This is the cost of the operation, tokens are charged per 1K tokens used, currently at .2 cents per 1K, this does not include picture generation which is about 20 cents each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6192\n"
     ]
    }
   ],
   "source": [
    "print(gptComp.total_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
